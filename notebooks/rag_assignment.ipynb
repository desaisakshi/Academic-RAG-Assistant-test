{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f650057-0548-46e3-8d20-f011e873d56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\balaj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tqdm as notebook_tqdm\n",
    "import glob\n",
    "from pypdf import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32c09d94-46cd-4f08-87e9-1bae124f2916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 61015\n"
     ]
    }
   ],
   "source": [
    "pdf_files = glob.glob(\"../data/ml_pdfs/*.pdf\")\n",
    "\n",
    "def extract_text(path):\n",
    "    reader = PdfReader(path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() or \"\"\n",
    "    return text\n",
    "\n",
    "documents = [extract_text(f) for f in pdf_files]\n",
    "full_text = \" \".join(documents)\n",
    "\n",
    "print(\"Total characters:\", len(full_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dd6e393-a57f-431e-9f49-d5f79c6369a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed chunks: 153\n"
     ]
    }
   ],
   "source": [
    "def fixed_chunk(text, size=500, overlap=100):\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), size-overlap):\n",
    "        chunks.append(text[i:i+size])\n",
    "    return chunks\n",
    "\n",
    "fixed_chunks = fixed_chunk(full_text)\n",
    "print(\"Fixed chunks:\", len(fixed_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae7df0ee-a17c-4530-a84d-0d5d6f4a7bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\balaj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\balaj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8279ca16-b971-475b-a439-e278a5e8af6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence chunks: 136\n"
     ]
    }
   ],
   "source": [
    "def sentence_chunk(text, max_size=500):\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    current = \"\"\n",
    "    for s in sentences:\n",
    "        if len(current) + len(s) < max_size:\n",
    "            current += \" \" + s\n",
    "        else:\n",
    "            chunks.append(current)\n",
    "            current = s\n",
    "    if current:\n",
    "        chunks.append(current)\n",
    "    return chunks\n",
    "\n",
    "sentence_chunks = sentence_chunk(full_text)\n",
    "print(\"Sentence chunks:\", len(sentence_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc2bd63e-9306-4f2e-afcf-0663d25b7b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|█████████████████████| 103/103 [00:00<00:00, 383.79it/s, Materializing param=pooler.dense.weight]\n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "fixed_embeddings = model.encode(fixed_chunks)\n",
    "sentence_embeddings = model.encode(sentence_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7865621-9fe1-4709-adc5-a9f5f67b36e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Validation error: name: Expected a name containing 3-512 characters from [a-zA-Z0-9._-], starting and ending with a character in [a-zA-Z0-9]. Got: ml",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m client = chromadb.Client()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m collection = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(fixed_chunks):\n\u001b[32m      5\u001b[39m     collection.add(\n\u001b[32m      6\u001b[39m         documents=[chunk],\n\u001b[32m      7\u001b[39m         embeddings=[fixed_embeddings[i].tolist()],\n\u001b[32m      8\u001b[39m         ids=[\u001b[38;5;28mstr\u001b[39m(i)]\n\u001b[32m      9\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\chromadb\\api\\client.py:210\u001b[39m, in \u001b[36mClient.create_collection\u001b[39m\u001b[34m(self, name, schema, configuration, metadata, embedding_function, data_loader, get_or_create)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m configuration_ef \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    208\u001b[39m     configuration[\u001b[33m\"\u001b[39m\u001b[33membedding_function\u001b[39m\u001b[33m\"\u001b[39m] = embedding_function\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_server\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Collection(\n\u001b[32m    220\u001b[39m     client=\u001b[38;5;28mself\u001b[39m._server,\n\u001b[32m    221\u001b[39m     model=model,\n\u001b[32m    222\u001b[39m     embedding_function=embedding_function,\n\u001b[32m    223\u001b[39m     data_loader=data_loader,\n\u001b[32m    224\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\chromadb\\api\\rust.py:243\u001b[39m, in \u001b[36mRustBindingsAPI.create_collection\u001b[39m\u001b[34m(self, name, schema, configuration, metadata, get_or_create, tenant, database)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    241\u001b[39m     schema_str = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m collection = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbindings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfiguration_json_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m collection_model = CollectionModel(\n\u001b[32m    253\u001b[39m     \u001b[38;5;28mid\u001b[39m=collection.id,\n\u001b[32m    254\u001b[39m     name=collection.name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    260\u001b[39m     database=collection.database,\n\u001b[32m    261\u001b[39m )\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m collection_model\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: Validation error: name: Expected a name containing 3-512 characters from [a-zA-Z0-9._-], starting and ending with a character in [a-zA-Z0-9]. Got: ml"
     ]
    }
   ],
   "source": [
    "client = chromadb.Client()\n",
    "collection = client.create_collection(\"ml\")\n",
    "\n",
    "for i, chunk in enumerate(fixed_chunks):\n",
    "    collection.add(\n",
    "        documents=[chunk],\n",
    "        embeddings=[fixed_embeddings[i].tolist()],\n",
    "        ids=[str(i)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06c6cd74-4e51-4ccd-b0d7-337329e64475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(\"ml_data\")  # ← fixed name\n",
    "\n",
    "for i, chunk in enumerate(fixed_chunks):\n",
    "    collection.add(\n",
    "        documents=[chunk],\n",
    "        embeddings=[fixed_embeddings[i].tolist()],\n",
    "        ids=[str(i)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a61f977-ce7d-47c7-9e48-200f1d42f7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, top_k=3):\n",
    "    query_embedding = model.encode([query])[0]\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding.tolist()],\n",
    "        n_results=top_k\n",
    "    )\n",
    "    return results[\"documents\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64dc4460-7400-40f1-a509-a78595add6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What is overfitting?\",\n",
    "    \"Explain bias-variance tradeoff.\",\n",
    "    \"What is regularization?\",\n",
    "    \"What is gradient descent?\",\n",
    "    \"What is cross validation?\",\n",
    "    \"Difference between classification and regression?\",\n",
    "    \"What is supervised learning?\",\n",
    "    \"What is feature engineering?\",\n",
    "    \"What is model evaluation?\",\n",
    "    \"What is logistic regression?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3ff7fa3-07ff-4a16-a6ff-bc914afd2ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: What is overfitting?\n",
      "ANSWER (retrieved context):\n",
      "\n",
      "answers (that is, the correct outputs), the algorithm iteratively makes predictions on the training data \n",
      "and is corrected by the teache r. Learning stops when the algorithm achieves an acceptable level of \n",
      "performance. \n",
      " \n",
      "Example \n",
      "Consider the following data regarding patients entering a clinic. The data consists of the gender \n",
      "and age of the patients and each patient is labeled as “healthy” or “sick”. \n",
      " \n",
      " \n",
      " \n",
      "1.5.2 Unsupervised learning \n",
      "Correct responses are not provided, but instead the algo\n",
      "============================================================\n",
      "QUESTION: Explain bias-variance tradeoff.\n",
      "ANSWER (retrieved context):\n",
      "mpling Theory: Error Estimation and Estimating Binomial Proportions, The \n",
      "Binomial Distribution, Estimators, Bias, and Variance   \n",
      " \n",
      " \n",
      "UNIT V:  \n",
      "Genetic Algorithms:  Motivation, Genetic Algorithms : Representing Hypotheses , Genetic Operator, \n",
      "Fitness Function and Selection,  An Illustrative  Example, Hypothesis Space Search, Genetic \n",
      "Programming, Models of Evolution and Learning : Lamarkian Evolution, Baldwin Effect , Parallelizing \n",
      "Genetic Algorithms. \n",
      " TEXT BOOKS:  \n",
      " \n",
      "1. Ethem  Alpaydin, ”Int\n",
      "============================================================\n",
      "QUESTION: What is regularization?\n",
      "ANSWER (retrieved context):\n",
      "s known as training. When the model has been trained, the \n",
      "data is transformed into an abstract form that summarizes the original information. \n",
      " \n",
      "3. Generalization \n",
      "The third component of the learning process is known as generalisation. \n",
      "The term generalization describes the process of turning the knowledge about stored data into a form \n",
      "that can be utilized for future action. These actions are to be carried out o n tasks that are similar, but \n",
      "not identical, to those what have been seen before.\n",
      "============================================================\n",
      "QUESTION: What is gradient descent?\n",
      "ANSWER (retrieved context):\n",
      "ovided and, based on this \n",
      "training set, the algorithm generalises to respond correctly to all possible inputs. This is also called \n",
      "learning from exemplars. Supervised learning is the machine learning task of learning a function that \n",
      "maps an input to an output based on example input-output pairs. \n",
      " \n",
      "In supervised learning, each example in the training set is a pair consisting of an input object \n",
      "(typically a vector) and an output value. A supervised learning algorithm analyzes the training dat\n",
      "============================================================\n",
      "QUESTION: What is cross validation?\n",
      "ANSWER (retrieved context):\n",
      "to be learned from the \n",
      "training experience and its unknown. For example, in a case of credit approval, the learning system will \n",
      "have customer application records as experience and task would be to classify whether the given \n",
      "customer application is eligible for a loan. So in this case, the training examples can be represented as \n",
      "8 \n",
      " \n",
      "(x1,y1)(x2,y2)..(xn,yn) where X represents customer application details and y represents the status of \n",
      "credit approval. \n",
      "With these details, what is that exact \n",
      "============================================================\n",
      "QUESTION: Difference between classification and regression?\n",
      "ANSWER (retrieved context):\n",
      "\n",
      "(typically a vector) and an output value. A supervised learning algorithm analyzes the training data and \n",
      "produces a function, which can be used for mapping new examples. I n the optimal case, the function \n",
      "will correctly determine the class labels for unseen instances. Both classification and regression \n",
      "13 \n",
      " \n",
      "problems are supervised learning problems. A wide range of supervised learning algorithms are \n",
      "available, each with its strengths and weaknesses. There is no single learning algorithm th\n",
      "============================================================\n",
      "QUESTION: What is supervised learning?\n",
      "ANSWER (retrieved context):\n",
      "ovided and, based on this \n",
      "training set, the algorithm generalises to respond correctly to all possible inputs. This is also called \n",
      "learning from exemplars. Supervised learning is the machine learning task of learning a function that \n",
      "maps an input to an output based on example input-output pairs. \n",
      " \n",
      "In supervised learning, each example in the training set is a pair consisting of an input object \n",
      "(typically a vector) and an output value. A supervised learning algorithm analyzes the training dat\n",
      "============================================================\n",
      "QUESTION: What is feature engineering?\n",
      "ANSWER (retrieved context):\n",
      "ther technology to retrieve data. \n",
      " \n",
      "2. Abstraction \n",
      "The second component of the learning process is known as abstraction. \n",
      "Abstraction is the process of extracting knowledge about stored data. This involves creating general \n",
      "concepts about the data as a whole. The creation of knowledge involves application of known models \n",
      "and creation of new models. \n",
      "The process of fitting a model to a dataset is known as training. When the model has been trained, the \n",
      "data is transformed into an abstract form\n",
      "============================================================\n",
      "QUESTION: What is model evaluation?\n",
      "ANSWER (retrieved context):\n",
      " be carried out o n tasks that are similar, but \n",
      "not identical, to those what have been seen before. In generalization, the goal is to discover those \n",
      "properties of the data that will be most relevant to future tasks. \n",
      " \n",
      "4. Evaluation \n",
      "Evaluation is the last component of the learning process. \n",
      "It is the process of giving feedback to the user to measure the utility of the learned knowledge. This \n",
      "feedback is then utilised to effect improvements in the whole learning process \n",
      " \n",
      "Applications of mac\n",
      "============================================================\n",
      "QUESTION: What is logistic regression?\n",
      "ANSWER (retrieved context):\n",
      "Logistic Regression, Neural Networks: Introduction, Perception, \n",
      "Multilayer Perception, Support Vector Machines: Linear and Non -Linear, Kernel Functions, K \n",
      "Nearest Neighbors. Introduction to clustering, K-means clustering, K-Mode Clustering. \n",
      " \n",
      "2.1. Decision Tree \n",
      "Introduction Decision Trees are a type of Supervised Machine Learning (that is you explain what \n",
      "the input is and what the corresponding output is in the training data) where the data is continuously \n",
      "split according to a certain par\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for q in questions:\n",
    "    print(\"QUESTION:\", q)\n",
    "    results = retrieve(q)\n",
    "    print(\"ANSWER (retrieved context):\")\n",
    "    print(results[0])\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2324c7-d758-4455-be49-e00d27ec597d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
